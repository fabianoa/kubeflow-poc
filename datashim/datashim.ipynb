{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "import kfp.dsl as dsl\n",
    "from kfp.aws import use_aws_secret\n",
    "from typing import NamedTuple\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In v1.1.0, in-cluster communication from notebook to Kubeflow Pipeline is not supported in this phase.\n",
    "# In order to use kfp as previous, user needs to pass a cookie to KFP for communication as a workaround.\n",
    "# https://www.kubeflow.org/docs/aws/pipeline/#authenticate-kubeflow-pipeline-using-sdk-inside-cluster\n",
    "\n",
    "#authservice_session='authservice_session=<cookie>'\n",
    "client = kfp.Client()\n",
    "#Mudar namespace\n",
    "namespace='fabiano-alencar'\n",
    "client.list_experiments(namespace=namespace)\n",
    "DATA_PATH = '/mnt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component: Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_path):\n",
    "    \n",
    "    import subprocess\n",
    "\n",
    "    # downlaod the dataset from the mlflow repo\n",
    "    def install():\n",
    "        subprocess.call(['apt-get', 'update'])\n",
    "        subprocess.call(['apt-get', 'install', 'ffmpeg', '-y'])\n",
    "        subprocess.call(['apt-get', 'install', 'libxext6', '-y'])\n",
    "        subprocess.call(['apt-get', 'install', 'libsm6', '-y'])\n",
    "        subprocess.call(['apt-get', 'install', 'libfontconfig1', '-y'])\n",
    "        subprocess.call(['apt-get', 'install', 'libxrender1', '-y'])\n",
    "        subprocess.call(['apt-get', 'install', 'libgl1-mesa-glx', '-y'])\n",
    "     \n",
    "    #install()\n",
    "    \n",
    "    #import cv2\n",
    "    import glob\n",
    "    \n",
    "    ext = ['png', 'jpg', 'gif']    # Add image formats here\n",
    "\n",
    "    files = []\n",
    "    [files.extend(glob.glob(data_path+\"/data/\" + '*.' + e)) for e in ext]\n",
    "    print(files)\n",
    "    #images = [cv2.imread(file) for file in files]\n",
    "    #print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_opencv_op = comp.func_to_container_op(process_data,\n",
    "                                             base_image='python:3.7-slim',\n",
    "                                             packages_to_install=['opencv-python','opencv-contrib-python','glob2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes.client.models import V1EnvVar\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='Training pipeline',\n",
    "    description='Training pipeline for time series forecasting on household power consumption dataset.'\n",
    "\n",
    ")\n",
    "def training_pipeline(data_path):\n",
    "    \n",
    "    http_proxy = V1EnvVar(name='http_proxy', value='http://10.190.24.159:3128')\n",
    "    https_proxy = V1EnvVar(name='https_proxy', value='http://10.190.24.159:3128')\n",
    "    no_proxy = V1EnvVar(name='no_proxy', value='mlflow.mlflow,minio-service.kubeflow')   \n",
    "    \n",
    "    \n",
    "    datasetName = \"example-dataset\"\n",
    "    kubeflow_pvc = dsl.PipelineVolume(datasetName)    \n",
    "    \n",
    "    process_opencv_task = process_opencv_op(data_path).set_display_name('Process Images') \\\n",
    "                .add_env_variable(http_proxy) \\\n",
    "                .add_env_variable(https_proxy) \\\n",
    "                .add_env_variable(no_proxy) \\\n",
    "                .add_pvolumes({data_path: kubeflow_pvc})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Pipeline Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/1da88e2a-037f-428c-a23e-cf36aae9abce\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/60e1b6ca-9c8d-44ef-8154-194fc5ba30bc\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=60e1b6ca-9c8d-44ef-8154-194fc5ba30bc)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arguments = {\"data_path\":DATA_PATH}\n",
    "experiment_name = 'minio_test'\n",
    "\n",
    "# Submit a pipeline run\n",
    "client.create_run_from_pipeline_func(\n",
    "    training_pipeline, arguments=arguments, namespace=namespace,experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the Pipeline to be reuseable by others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(training_pipeline, 'workflow.yaml')\n",
    "\n",
    "\n",
    "#client.upload_pipeline(pipeline_package_path='workflow.yaml',\n",
    "#                             pipeline_name='Electric Power Consumption Forecasting Training Pipeline.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "gcr.io/arrikto-public/tensorflow-1.15.2-notebook-cpu:1.0.0.arr1",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "pipeline_description": "",
   "pipeline_name": "",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "workspace-server-k451mcy01",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
